{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from pytorch_model_summary import summary\n",
    "import shutil\n",
    "\n",
    "sys.path.insert(1, '../utils')\n",
    "sys.path.insert(1, '../models')\n",
    "\n",
    "from data import StutterData, load_data\n",
    "from audioCNN import AudioCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AudioCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "          Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "===========================================================================\n",
      "   AdaptiveAvgPool2d-1      [1, 1, 20, 50]               0               0\n",
      "              Conv2d-2      [1, 1, 32, 32]              80              80\n",
      "   AdaptiveAvgPool2d-3      [1, 8, 30, 30]               0               0\n",
      "             Dropout-4      [1, 8, 16, 16]               0               0\n",
      "              Conv2d-5      [1, 8, 16, 16]           1,168           1,168\n",
      "   AdaptiveAvgPool2d-6     [1, 16, 14, 14]               0               0\n",
      "              Linear-7           [1, 1024]         524,800         524,800\n",
      "              Linear-8            [1, 512]         131,328         131,328\n",
      "              Linear-9            [1, 256]             257             257\n",
      "===========================================================================\n",
      "Total params: 657,633\n",
      "Trainable params: 657,633\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(AudioCNN(), torch.zeros((1, 1, 20, 50)), show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0122]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.zeros((1, 1, 20, 50)))  # Test forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 1\n",
    "epochs = 25\n",
    "validation_split=0.2\n",
    "shuffle_dataset=True\n",
    "random_seed=42\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")     #Check whether a GPU is present.\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr = 0.00001, momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 200], gamma=0.1)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StutterData('../data/*')\n",
    "train_loader, validation_loader = load_data(dataset, batch_size, validation_split=0.2, shuffle_dataset=True, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioCNN(\n",
       "  (maxpool): AdaptiveAvgPool2d(output_size=32)\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool1): AdaptiveAvgPool2d(output_size=16)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool2): AdaptiveAvgPool2d(output_size=8)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index : 0 Loss : 0.0614712387 Time : 0.016 seconds \n",
      "Batch Index : 100 Loss : 1.4136889238 Time : 1.735 seconds \n",
      "Batch Index : 200 Loss : 1.0112973245 Time : 3.703 seconds \n",
      "Batch Index : 300 Loss : 0.8644421383 Time : 5.735 seconds \n",
      "Batch Index : 400 Loss : 0.7959458611 Time : 7.434 seconds \n",
      "Batch Index : 500 Loss : 0.7615691856 Time : 8.987 seconds \n",
      "Batch Index : 600 Loss : 0.7337328635 Time : 10.661 seconds \n",
      "Epoch : 0 Val_Acc : 66.667 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n",
      "Validation loss decreased (inf --> 0.313262).  Saving model ...\n",
      "Batch Index : 0 Loss : 0.7301947102 Time : 0.029 seconds \n",
      "Batch Index : 100 Loss : 0.5973110587 Time : 1.779 seconds \n",
      "Batch Index : 200 Loss : 0.5892476275 Time : 3.401 seconds \n",
      "Batch Index : 300 Loss : 0.5678401484 Time : 4.995 seconds \n",
      "Batch Index : 400 Loss : 0.5740428980 Time : 6.588 seconds \n",
      "Batch Index : 500 Loss : 0.5897502337 Time : 8.224 seconds \n",
      "Batch Index : 600 Loss : 0.5963254225 Time : 9.792 seconds \n",
      "Epoch : 1 Val_Acc : 75.926 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.1234325096 Time : 0.025 seconds \n",
      "Batch Index : 100 Loss : 0.5914944100 Time : 1.541 seconds \n",
      "Batch Index : 200 Loss : 0.5654673281 Time : 3.181 seconds \n",
      "Batch Index : 300 Loss : 0.5433392875 Time : 4.842 seconds \n",
      "Batch Index : 400 Loss : 0.5438988981 Time : 6.430 seconds \n",
      "Batch Index : 500 Loss : 0.5407739995 Time : 7.956 seconds \n",
      "Batch Index : 600 Loss : 0.5451381611 Time : 9.587 seconds \n",
      "Epoch : 2 Val_Acc : 74.691 Val_loss: 1.313\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.3304687440 Time : 0.017 seconds \n",
      "Batch Index : 100 Loss : 0.4952831502 Time : 1.894 seconds \n",
      "Batch Index : 200 Loss : 0.5141978095 Time : 3.526 seconds \n",
      "Batch Index : 300 Loss : 0.5110481110 Time : 5.175 seconds \n",
      "Batch Index : 400 Loss : 0.5143423676 Time : 7.119 seconds \n",
      "Batch Index : 500 Loss : 0.5186024407 Time : 9.165 seconds \n",
      "Batch Index : 600 Loss : 0.5274248234 Time : 10.998 seconds \n",
      "Epoch : 3 Val_Acc : 74.691 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 1.2128665745 Time : 0.016 seconds \n",
      "Batch Index : 100 Loss : 0.5860824131 Time : 1.619 seconds \n",
      "Batch Index : 200 Loss : 0.5486697139 Time : 3.250 seconds \n",
      "Batch Index : 300 Loss : 0.5444089641 Time : 4.948 seconds \n",
      "Batch Index : 400 Loss : 0.5215041881 Time : 7.077 seconds \n",
      "Batch Index : 500 Loss : 0.5133703094 Time : 9.302 seconds \n",
      "Batch Index : 600 Loss : 0.5232294149 Time : 11.302 seconds \n",
      "Epoch : 4 Val_Acc : 77.160 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.4571259022 Time : 0.016 seconds \n",
      "Batch Index : 100 Loss : 0.4692665763 Time : 1.624 seconds \n",
      "Batch Index : 200 Loss : 0.4480885141 Time : 3.292 seconds \n",
      "Batch Index : 300 Loss : 0.4435148509 Time : 4.837 seconds \n",
      "Batch Index : 400 Loss : 0.4470821738 Time : 6.524 seconds \n",
      "Batch Index : 500 Loss : 0.4506666049 Time : 8.101 seconds \n",
      "Batch Index : 600 Loss : 0.4627672095 Time : 9.630 seconds \n",
      "Epoch : 5 Val_Acc : 70.988 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n",
      "Validation loss decreased (0.313262 --> 0.313262).  Saving model ...\n",
      "Batch Index : 0 Loss : 0.0038833222 Time : 0.049 seconds \n",
      "Batch Index : 100 Loss : 0.4829656809 Time : 1.975 seconds \n",
      "Batch Index : 200 Loss : 0.4956433363 Time : 3.714 seconds \n",
      "Batch Index : 300 Loss : 0.4897267120 Time : 5.591 seconds \n",
      "Batch Index : 400 Loss : 0.4946012317 Time : 7.467 seconds \n",
      "Batch Index : 500 Loss : 0.4935144034 Time : 9.357 seconds \n",
      "Batch Index : 600 Loss : 0.4942892332 Time : 11.078 seconds \n",
      "Epoch : 6 Val_Acc : 73.457 Val_loss: 1.313\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0071759815 Time : 0.022 seconds \n",
      "Batch Index : 100 Loss : 0.4689950861 Time : 1.610 seconds \n",
      "Batch Index : 200 Loss : 0.4816865660 Time : 3.241 seconds \n",
      "Batch Index : 300 Loss : 0.4757857653 Time : 4.869 seconds \n",
      "Batch Index : 400 Loss : 0.4537955024 Time : 6.466 seconds \n",
      "Batch Index : 500 Loss : 0.4593759545 Time : 8.065 seconds \n",
      "Batch Index : 600 Loss : 0.4708452456 Time : 9.616 seconds \n",
      "Epoch : 7 Val_Acc : 72.840 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.2026462555 Time : 0.016 seconds \n",
      "Batch Index : 100 Loss : 0.5229971456 Time : 1.561 seconds \n",
      "Batch Index : 200 Loss : 0.5384911329 Time : 3.185 seconds \n",
      "Batch Index : 300 Loss : 0.5203042892 Time : 4.823 seconds \n",
      "Batch Index : 400 Loss : 0.4656593039 Time : 6.440 seconds \n",
      "Batch Index : 500 Loss : 0.4807908844 Time : 8.045 seconds \n",
      "Batch Index : 600 Loss : 0.4699694758 Time : 9.606 seconds \n",
      "Epoch : 8 Val_Acc : 77.160 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0621314123 Time : 0.015 seconds \n",
      "Batch Index : 100 Loss : 0.3933111146 Time : 2.144 seconds \n",
      "Batch Index : 200 Loss : 0.3932109506 Time : 4.057 seconds \n",
      "Batch Index : 300 Loss : 0.3917868673 Time : 5.756 seconds \n",
      "Batch Index : 400 Loss : 0.4192984193 Time : 8.045 seconds \n",
      "Batch Index : 500 Loss : 0.4387630512 Time : 9.975 seconds \n",
      "Batch Index : 600 Loss : 0.4378497194 Time : 11.816 seconds \n",
      "Epoch : 9 Val_Acc : 74.691 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 1.2580819726 Time : 0.020 seconds \n",
      "Batch Index : 100 Loss : 0.3644422783 Time : 2.677 seconds \n",
      "Batch Index : 200 Loss : 0.4866910353 Time : 4.870 seconds \n",
      "Batch Index : 300 Loss : 0.4630738942 Time : 7.078 seconds \n",
      "Batch Index : 400 Loss : 0.4447422707 Time : 8.962 seconds \n",
      "Batch Index : 500 Loss : 0.4587411588 Time : 10.781 seconds \n",
      "Batch Index : 600 Loss : 0.4637991657 Time : 12.778 seconds \n",
      "Epoch : 10 Val_Acc : 76.543 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n",
      "Validation loss decreased (0.313262 --> 0.313262).  Saving model ...\n",
      "Batch Index : 0 Loss : 0.0026293965 Time : 0.016 seconds \n",
      "Batch Index : 100 Loss : 0.5780535826 Time : 1.851 seconds \n",
      "Batch Index : 200 Loss : 0.4977754193 Time : 3.866 seconds \n",
      "Batch Index : 300 Loss : 0.5038571475 Time : 6.115 seconds \n",
      "Batch Index : 400 Loss : 0.4542205045 Time : 8.144 seconds \n",
      "Batch Index : 500 Loss : 0.4409307242 Time : 9.815 seconds \n",
      "Batch Index : 600 Loss : 0.4417376761 Time : 11.704 seconds \n",
      "Epoch : 11 Val_Acc : 77.160 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n",
      "Validation loss decreased (0.313262 --> 0.313262).  Saving model ...\n",
      "Batch Index : 0 Loss : 0.6633973122 Time : 0.039 seconds \n",
      "Batch Index : 100 Loss : 0.3642645276 Time : 2.042 seconds \n",
      "Batch Index : 200 Loss : 0.3936250355 Time : 3.945 seconds \n",
      "Batch Index : 300 Loss : 0.4542039081 Time : 5.878 seconds \n",
      "Batch Index : 400 Loss : 0.4654673898 Time : 7.535 seconds \n",
      "Batch Index : 500 Loss : 0.4207588288 Time : 9.207 seconds \n",
      "Batch Index : 600 Loss : 0.4275054262 Time : 10.895 seconds \n",
      "Epoch : 12 Val_Acc : 75.926 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n",
      "Validation loss decreased (0.313262 --> 0.313262).  Saving model ...\n",
      "Batch Index : 0 Loss : 0.0295741670 Time : 0.038 seconds \n",
      "Batch Index : 100 Loss : 0.4661197008 Time : 1.767 seconds \n",
      "Batch Index : 200 Loss : 0.4730517392 Time : 3.471 seconds \n",
      "Batch Index : 300 Loss : 0.4448167488 Time : 5.220 seconds \n",
      "Batch Index : 400 Loss : 0.4401238789 Time : 6.989 seconds \n",
      "Batch Index : 500 Loss : 0.4174588836 Time : 8.603 seconds \n",
      "Batch Index : 600 Loss : 0.4069553253 Time : 10.386 seconds \n",
      "Epoch : 13 Val_Acc : 69.136 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n",
      "Validation loss decreased (0.313262 --> 0.313262).  Saving model ...\n",
      "Batch Index : 0 Loss : 0.0834640637 Time : 0.040 seconds \n",
      "Batch Index : 100 Loss : 0.4123870562 Time : 1.754 seconds \n",
      "Batch Index : 200 Loss : 0.4372114267 Time : 3.329 seconds \n",
      "Batch Index : 300 Loss : 0.4355859913 Time : 5.095 seconds \n",
      "Batch Index : 400 Loss : 0.4129612414 Time : 6.831 seconds \n",
      "Batch Index : 500 Loss : 0.4014036387 Time : 8.502 seconds \n",
      "Batch Index : 600 Loss : 0.3936943846 Time : 10.101 seconds \n",
      "Epoch : 14 Val_Acc : 75.926 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n",
      "Validation loss decreased (0.313262 --> 0.313262).  Saving model ...\n",
      "Batch Index : 0 Loss : 0.3469507098 Time : 0.050 seconds \n",
      "Batch Index : 100 Loss : 0.3105431855 Time : 1.781 seconds \n",
      "Batch Index : 200 Loss : 0.3410727514 Time : 3.383 seconds \n",
      "Batch Index : 300 Loss : 0.3549424544 Time : 5.020 seconds \n",
      "Batch Index : 400 Loss : 0.3756672187 Time : 6.675 seconds \n",
      "Batch Index : 500 Loss : 0.3935249899 Time : 8.354 seconds \n",
      "Batch Index : 600 Loss : 0.3814587487 Time : 10.012 seconds \n",
      "Epoch : 15 Val_Acc : 72.840 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.3475494683 Time : 0.015 seconds \n",
      "Batch Index : 100 Loss : 0.3075912943 Time : 1.604 seconds \n",
      "Batch Index : 200 Loss : 0.3525612815 Time : 3.252 seconds \n",
      "Batch Index : 300 Loss : 0.4196526478 Time : 4.996 seconds \n",
      "Batch Index : 400 Loss : 0.4268532386 Time : 6.916 seconds \n",
      "Batch Index : 500 Loss : 0.4400542941 Time : 9.412 seconds \n",
      "Batch Index : 600 Loss : 0.4216837879 Time : 11.349 seconds \n",
      "Epoch : 16 Val_Acc : 74.691 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n",
      "Validation loss decreased (0.313262 --> 0.313262).  Saving model ...\n",
      "Batch Index : 0 Loss : 0.0014221088 Time : 0.044 seconds \n",
      "Batch Index : 100 Loss : 0.3712011542 Time : 1.886 seconds \n",
      "Batch Index : 200 Loss : 0.3490037698 Time : 3.990 seconds \n",
      "Batch Index : 300 Loss : 0.3430164191 Time : 5.846 seconds \n",
      "Batch Index : 400 Loss : 0.3691728176 Time : 7.614 seconds \n",
      "Batch Index : 500 Loss : 0.3805737294 Time : 9.365 seconds \n",
      "Batch Index : 600 Loss : 0.3684293253 Time : 11.648 seconds \n",
      "Epoch : 17 Val_Acc : 74.074 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0585527793 Time : 0.015 seconds \n",
      "Batch Index : 100 Loss : 0.2015440625 Time : 1.745 seconds \n",
      "Batch Index : 200 Loss : 0.3490285296 Time : 3.649 seconds \n",
      "Batch Index : 300 Loss : 0.4047285160 Time : 5.576 seconds \n",
      "Batch Index : 400 Loss : 0.3766327243 Time : 7.510 seconds \n",
      "Batch Index : 500 Loss : 0.3621660730 Time : 9.813 seconds \n",
      "Batch Index : 600 Loss : 0.3788560849 Time : 11.599 seconds \n",
      "Epoch : 18 Val_Acc : 77.160 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0825835094 Time : 0.026 seconds \n",
      "Batch Index : 100 Loss : 0.3599926396 Time : 2.364 seconds \n",
      "Batch Index : 200 Loss : 0.4419075198 Time : 4.828 seconds \n",
      "Batch Index : 300 Loss : 0.3958189982 Time : 7.206 seconds \n",
      "Batch Index : 400 Loss : 0.3754448013 Time : 8.956 seconds \n",
      "Batch Index : 500 Loss : 0.3900136188 Time : 10.813 seconds \n",
      "Batch Index : 600 Loss : 0.3804521684 Time : 12.505 seconds \n",
      "Epoch : 19 Val_Acc : 75.309 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.9102559090 Time : 0.017 seconds \n",
      "Batch Index : 100 Loss : 0.3299810748 Time : 1.936 seconds \n",
      "Batch Index : 200 Loss : 0.3456529910 Time : 3.714 seconds \n",
      "Batch Index : 300 Loss : 0.3217782760 Time : 5.462 seconds \n",
      "Batch Index : 400 Loss : 0.3606885520 Time : 7.703 seconds \n",
      "Batch Index : 500 Loss : 0.3727816377 Time : 9.517 seconds \n",
      "Batch Index : 600 Loss : 0.3628215607 Time : 11.409 seconds \n",
      "Epoch : 20 Val_Acc : 75.926 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n",
      "Validation loss decreased (0.313262 --> 0.313262).  Saving model ...\n",
      "Batch Index : 0 Loss : 0.0004582547 Time : 0.037 seconds \n",
      "Batch Index : 100 Loss : 0.3412198988 Time : 1.742 seconds \n",
      "Batch Index : 200 Loss : 0.3456521113 Time : 3.435 seconds \n",
      "Batch Index : 300 Loss : 0.3526680365 Time : 5.076 seconds \n",
      "Batch Index : 400 Loss : 0.3177591671 Time : 6.781 seconds \n",
      "Batch Index : 500 Loss : 0.3505866199 Time : 8.421 seconds \n",
      "Batch Index : 600 Loss : 0.3449941540 Time : 10.069 seconds \n",
      "Epoch : 21 Val_Acc : 83.951 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n",
      "Validation loss decreased (0.313262 --> 0.313262).  Saving model ...\n",
      "Batch Index : 0 Loss : 0.7594503909 Time : 0.047 seconds \n",
      "Batch Index : 100 Loss : 0.2740301030 Time : 1.714 seconds \n",
      "Batch Index : 200 Loss : 0.3298032908 Time : 3.367 seconds \n",
      "Batch Index : 300 Loss : 0.3433053972 Time : 5.057 seconds \n",
      "Batch Index : 400 Loss : 0.3461794709 Time : 6.698 seconds \n",
      "Batch Index : 500 Loss : 0.3437028703 Time : 8.463 seconds \n",
      "Batch Index : 600 Loss : 0.3562710540 Time : 10.123 seconds \n",
      "Epoch : 22 Val_Acc : 79.630 Val_loss: 0.693\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.9504563510 Time : 0.017 seconds \n",
      "Batch Index : 100 Loss : 0.3261288504 Time : 1.787 seconds \n",
      "Batch Index : 200 Loss : 0.2653983703 Time : 3.462 seconds \n",
      "Batch Index : 300 Loss : 0.2947679487 Time : 5.095 seconds \n",
      "Batch Index : 400 Loss : 0.3067081604 Time : 6.798 seconds \n",
      "Batch Index : 500 Loss : 0.3377224273 Time : 8.686 seconds \n",
      "Batch Index : 600 Loss : 0.3461556214 Time : 10.369 seconds \n",
      "Epoch : 23 Val_Acc : 75.309 Val_loss: 1.313\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.1053356752 Time : 0.024 seconds \n",
      "Batch Index : 100 Loss : 0.3652039600 Time : 1.963 seconds \n",
      "Batch Index : 200 Loss : 0.3566014782 Time : 3.797 seconds \n",
      "Batch Index : 300 Loss : 0.3609542863 Time : 5.582 seconds \n",
      "Batch Index : 400 Loss : 0.3477073047 Time : 7.434 seconds \n",
      "Batch Index : 500 Loss : 0.3282272111 Time : 9.328 seconds \n",
      "Batch Index : 600 Loss : 0.3421722187 Time : 11.186 seconds \n",
      "Epoch : 24 Val_Acc : 74.074 Val_loss: 1.313\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "valid_loss_min = float('inf') #init val_loss\n",
    "checkpoint_path = '../models/audioCNN_ckpt.pth'\n",
    "best_model_path = '../models/audioCNN_best_ckpt.pth'\n",
    "for epoch in range(epochs):\n",
    "    losses=[]\n",
    "#     scheduler.step()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for b_idx, x in enumerate(train_loader):\n",
    "#         print(b_idx)\n",
    "        inputs, targets = x['mfcc'].to(device), x['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        op = model(inputs).view(-1)\n",
    "#         print(op[0], targets[0])\n",
    "#         print(type(op.view(-1)[0]), type(targets[0]))\n",
    "#         print(b_idx, op)\n",
    "#         print(targets)\n",
    "        loss = criterion(op, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        end = time.time()\n",
    "        if b_idx % 100 == 0:\n",
    "            print('Batch Index : %d Loss : %.10f Time : %.3f seconds ' % (b_idx, np.mean(losses), end - start))    \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for b_idx, x in enumerate(validation_loader):\n",
    "            inputs, targets = x['mfcc'].to(device), x['label'].to(device)\n",
    "\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "#             print(outputs, targets)\n",
    "            \n",
    "            \n",
    "            predicted = torch.round(outputs.data)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "            valid_loss = criterion(predicted.view(-1), targets.data)\n",
    "            acc = 100.*correct/total\n",
    "        print('Epoch : %d Val_Acc : %.3f Val_loss: %.3f' % (epoch, acc, valid_loss))\n",
    "        print('--------------------------------------------------------------')\n",
    "    checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'valid_loss_min': valid_loss,\n",
    "            'valid_acc': acc,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "\n",
    "    save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "    \n",
    "    if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    model.train()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bolo",
   "language": "python",
   "name": "bolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

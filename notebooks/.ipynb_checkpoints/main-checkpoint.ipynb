{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "from data import StutterData, load_data\n",
    "from audioCNN import AudioCNN\n",
    "sys.path.insert(1, '../utils')\n",
    "sys.path.insert(1, '../models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AudioCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "          Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "===========================================================================\n",
      "   AdaptiveAvgPool2d-1      [1, 1, 20, 50]               0               0\n",
      "              Conv2d-2      [1, 1, 32, 32]              80              80\n",
      "   AdaptiveAvgPool2d-3      [1, 8, 30, 30]               0               0\n",
      "             Dropout-4      [1, 8, 16, 16]               0               0\n",
      "              Conv2d-5      [1, 8, 16, 16]           1,168           1,168\n",
      "   AdaptiveAvgPool2d-6     [1, 16, 14, 14]               0               0\n",
      "              Linear-7           [1, 1024]         524,800         524,800\n",
      "              Linear-8            [1, 512]         131,328         131,328\n",
      "              Linear-9            [1, 256]             257             257\n",
      "===========================================================================\n",
      "Total params: 657,633\n",
      "Trainable params: 657,633\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(AudioCNN(), torch.zeros((1, 1, 20, 50)), show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0223]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.zeros((1, 1, 20, 50)))  # Test forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 1\n",
    "epochs = 25\n",
    "validation_split=0.2\n",
    "shuffle_dataset=True\n",
    "random_seed=42\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")     #Check whether a GPU is present.\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr = 0.00001, momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 200], gamma=0.1)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StutterData('../data/*')\n",
    "train_loader, validation_loader = load_data(dataset, batch_size, validation_split=0.2, shuffle_dataset=True, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioCNN(\n",
       "  (maxpool): AdaptiveAvgPool2d(output_size=32)\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool1): AdaptiveAvgPool2d(output_size=16)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool2): AdaptiveAvgPool2d(output_size=8)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index : 0 Loss : 0.4677416980 Time : 0.037 seconds \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=87\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=2037\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index : 100 Loss : 2.0208862932 Time : 1.557 seconds \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1684\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=2001\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index : 200 Loss : 1.3437594945 Time : 3.081 seconds \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1410\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index : 300 Loss : 1.1371808386 Time : 4.611 seconds \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1924\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index : 400 Loss : 0.9992247552 Time : 6.041 seconds \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1959\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1723\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index : 500 Loss : 0.9007035680 Time : 7.597 seconds \n",
      "Batch Index : 600 Loss : 0.8647993472 Time : 9.154 seconds \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1232\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1527\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1567\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1566\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Test Acc : 70.988\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0022342261 Time : 0.016 seconds \n",
      "Batch Index : 100 Loss : 0.6000503644 Time : 1.646 seconds \n",
      "Batch Index : 200 Loss : 0.6178291156 Time : 3.175 seconds \n",
      "Batch Index : 300 Loss : 0.5653711273 Time : 4.687 seconds \n",
      "Batch Index : 400 Loss : 0.5495143026 Time : 6.230 seconds \n",
      "Batch Index : 500 Loss : 0.5179374696 Time : 7.661 seconds \n",
      "Batch Index : 600 Loss : 0.4842537235 Time : 9.152 seconds \n",
      "Epoch : 1 Test Acc : 69.753\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.7696097940 Time : 0.013 seconds \n",
      "Batch Index : 100 Loss : 0.5142220698 Time : 1.555 seconds \n",
      "Batch Index : 200 Loss : 0.5243332758 Time : 3.081 seconds \n",
      "Batch Index : 300 Loss : 0.5038621939 Time : 4.554 seconds \n",
      "Batch Index : 400 Loss : 0.4928203464 Time : 6.058 seconds \n",
      "Batch Index : 500 Loss : 0.4866966558 Time : 7.495 seconds \n",
      "Batch Index : 600 Loss : 0.4913943398 Time : 9.034 seconds \n",
      "Epoch : 2 Test Acc : 77.778\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.7392671630 Time : 0.021 seconds \n",
      "Batch Index : 100 Loss : 0.4688547499 Time : 1.593 seconds \n",
      "Batch Index : 200 Loss : 0.4404070132 Time : 3.112 seconds \n",
      "Batch Index : 300 Loss : 0.4741962764 Time : 4.583 seconds \n",
      "Batch Index : 400 Loss : 0.4469643101 Time : 6.133 seconds \n",
      "Batch Index : 500 Loss : 0.4558732465 Time : 7.609 seconds \n",
      "Batch Index : 600 Loss : 0.4613205837 Time : 9.080 seconds \n",
      "Epoch : 3 Test Acc : 76.543\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0095221382 Time : 0.016 seconds \n",
      "Batch Index : 100 Loss : 0.4260528288 Time : 1.697 seconds \n",
      "Batch Index : 200 Loss : 0.3940877765 Time : 3.312 seconds \n",
      "Batch Index : 300 Loss : 0.4182866364 Time : 4.800 seconds \n",
      "Batch Index : 400 Loss : 0.4436443578 Time : 6.297 seconds \n",
      "Batch Index : 500 Loss : 0.4609959718 Time : 7.801 seconds \n",
      "Batch Index : 600 Loss : 0.4686769164 Time : 9.265 seconds \n",
      "Epoch : 4 Test Acc : 77.778\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0000003576 Time : 0.019 seconds \n",
      "Batch Index : 100 Loss : 0.4368973701 Time : 1.533 seconds \n",
      "Batch Index : 200 Loss : 0.4563939827 Time : 3.048 seconds \n",
      "Batch Index : 300 Loss : 0.4325845259 Time : 4.566 seconds \n",
      "Batch Index : 400 Loss : 0.4190967660 Time : 6.135 seconds \n",
      "Batch Index : 500 Loss : 0.4235363547 Time : 7.701 seconds \n",
      "Batch Index : 600 Loss : 0.4312108047 Time : 9.359 seconds \n",
      "Epoch : 5 Test Acc : 79.630\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0602736063 Time : 0.016 seconds \n",
      "Batch Index : 100 Loss : 0.3753741284 Time : 1.584 seconds \n",
      "Batch Index : 200 Loss : 0.3732634377 Time : 3.105 seconds \n",
      "Batch Index : 300 Loss : 0.3151919479 Time : 4.768 seconds \n",
      "Batch Index : 400 Loss : 0.3772150951 Time : 6.327 seconds \n",
      "Batch Index : 500 Loss : 0.4049050197 Time : 7.968 seconds \n",
      "Batch Index : 600 Loss : 0.4013583499 Time : 9.516 seconds \n",
      "Epoch : 6 Test Acc : 78.395\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.9912101924 Time : 0.016 seconds \n",
      "Batch Index : 100 Loss : 0.4497741673 Time : 1.591 seconds \n",
      "Batch Index : 200 Loss : 0.4308544626 Time : 3.288 seconds \n",
      "Batch Index : 300 Loss : 0.4097980204 Time : 4.996 seconds \n",
      "Batch Index : 400 Loss : 0.3948078588 Time : 7.002 seconds \n",
      "Batch Index : 500 Loss : 0.3915232010 Time : 8.658 seconds \n",
      "Batch Index : 600 Loss : 0.4023925159 Time : 10.205 seconds \n",
      "Epoch : 7 Test Acc : 79.012\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.2511778176 Time : 0.015 seconds \n",
      "Batch Index : 100 Loss : 0.3587107573 Time : 1.738 seconds \n",
      "Batch Index : 200 Loss : 0.3629885889 Time : 3.428 seconds \n",
      "Batch Index : 300 Loss : 0.3719297202 Time : 5.063 seconds \n",
      "Batch Index : 400 Loss : 0.3710189660 Time : 6.642 seconds \n",
      "Batch Index : 500 Loss : 0.3815765990 Time : 8.280 seconds \n",
      "Batch Index : 600 Loss : 0.3932411121 Time : 9.880 seconds \n",
      "Epoch : 8 Test Acc : 77.778\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.5375920534 Time : 0.014 seconds \n",
      "Batch Index : 100 Loss : 0.4051797642 Time : 1.641 seconds \n",
      "Batch Index : 200 Loss : 0.4164182264 Time : 3.298 seconds \n",
      "Batch Index : 300 Loss : 0.3987643630 Time : 4.994 seconds \n",
      "Batch Index : 400 Loss : 0.3924848049 Time : 6.621 seconds \n",
      "Batch Index : 500 Loss : 0.4102998691 Time : 8.168 seconds \n",
      "Batch Index : 600 Loss : 0.3990002811 Time : 9.773 seconds \n",
      "Epoch : 9 Test Acc : 72.840\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.1838734001 Time : 0.014 seconds \n",
      "Batch Index : 100 Loss : 0.3792650145 Time : 1.586 seconds \n",
      "Batch Index : 200 Loss : 0.4016712067 Time : 3.128 seconds \n",
      "Batch Index : 300 Loss : 0.3853788327 Time : 4.740 seconds \n",
      "Batch Index : 400 Loss : 0.3814098107 Time : 6.379 seconds \n",
      "Batch Index : 500 Loss : 0.3836314881 Time : 8.082 seconds \n",
      "Batch Index : 600 Loss : 0.3915659265 Time : 10.268 seconds \n",
      "Epoch : 10 Test Acc : 77.160\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.1253019720 Time : 0.013 seconds \n",
      "Batch Index : 100 Loss : 0.3135669102 Time : 1.583 seconds \n",
      "Batch Index : 200 Loss : 0.3762608554 Time : 3.165 seconds \n",
      "Batch Index : 300 Loss : 0.3834393414 Time : 4.727 seconds \n",
      "Batch Index : 400 Loss : 0.3705345478 Time : 6.252 seconds \n",
      "Batch Index : 500 Loss : 0.3663158874 Time : 7.798 seconds \n",
      "Batch Index : 600 Loss : 0.3572028911 Time : 9.386 seconds \n",
      "Epoch : 11 Test Acc : 72.840\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.7977301478 Time : 0.015 seconds \n",
      "Batch Index : 100 Loss : 0.5137309341 Time : 1.692 seconds \n",
      "Batch Index : 200 Loss : 0.4664824161 Time : 3.227 seconds \n",
      "Batch Index : 300 Loss : 0.4289055581 Time : 4.802 seconds \n",
      "Batch Index : 400 Loss : 0.4131444482 Time : 6.402 seconds \n",
      "Batch Index : 500 Loss : 0.3955236057 Time : 7.974 seconds \n",
      "Batch Index : 600 Loss : 0.3834392431 Time : 9.540 seconds \n",
      "Epoch : 12 Test Acc : 80.247\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0954691693 Time : 0.015 seconds \n",
      "Batch Index : 100 Loss : 0.3354514419 Time : 1.560 seconds \n",
      "Batch Index : 200 Loss : 0.3606376519 Time : 3.105 seconds \n",
      "Batch Index : 300 Loss : 0.3831906463 Time : 4.602 seconds \n",
      "Batch Index : 400 Loss : 0.3761845156 Time : 6.232 seconds \n",
      "Batch Index : 500 Loss : 0.3591543101 Time : 7.893 seconds \n",
      "Batch Index : 600 Loss : 0.3760142530 Time : 9.635 seconds \n",
      "Epoch : 13 Test Acc : 80.864\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0000107288 Time : 0.018 seconds \n",
      "Batch Index : 100 Loss : 0.3671264643 Time : 1.531 seconds \n",
      "Batch Index : 200 Loss : 0.3356994912 Time : 3.109 seconds \n",
      "Batch Index : 300 Loss : 0.3467750118 Time : 4.713 seconds \n",
      "Batch Index : 400 Loss : 0.3380116238 Time : 6.245 seconds \n",
      "Batch Index : 500 Loss : 0.3382893214 Time : 7.938 seconds \n",
      "Batch Index : 600 Loss : 0.3473508857 Time : 9.584 seconds \n",
      "Epoch : 14 Test Acc : 82.099\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0126083400 Time : 0.019 seconds \n",
      "Batch Index : 100 Loss : 0.2443898903 Time : 1.571 seconds \n",
      "Batch Index : 200 Loss : 0.3117375134 Time : 3.162 seconds \n",
      "Batch Index : 300 Loss : 0.3209981142 Time : 4.762 seconds \n",
      "Batch Index : 400 Loss : 0.3304450499 Time : 6.351 seconds \n",
      "Batch Index : 500 Loss : 0.3150783725 Time : 7.998 seconds \n",
      "Batch Index : 600 Loss : 0.2973455841 Time : 9.520 seconds \n",
      "Epoch : 15 Test Acc : 77.160\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.1378637552 Time : 0.013 seconds \n",
      "Batch Index : 100 Loss : 0.2937417163 Time : 1.622 seconds \n",
      "Batch Index : 200 Loss : 0.3155680937 Time : 3.172 seconds \n",
      "Batch Index : 300 Loss : 0.3077400966 Time : 4.780 seconds \n",
      "Batch Index : 400 Loss : 0.3054530641 Time : 6.503 seconds \n",
      "Batch Index : 500 Loss : 0.2795306035 Time : 8.379 seconds \n",
      "Batch Index : 600 Loss : 0.3064023968 Time : 10.135 seconds \n",
      "Epoch : 16 Test Acc : 72.840\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.5588846207 Time : 0.018 seconds \n",
      "Batch Index : 100 Loss : 0.2934521724 Time : 1.801 seconds \n",
      "Batch Index : 200 Loss : 0.2874011858 Time : 3.501 seconds \n",
      "Batch Index : 300 Loss : 0.3370052352 Time : 5.216 seconds \n",
      "Batch Index : 400 Loss : 0.4629029004 Time : 7.167 seconds \n",
      "Batch Index : 500 Loss : 0.4505953120 Time : 9.041 seconds \n",
      "Batch Index : 600 Loss : 0.4380064860 Time : 11.098 seconds \n",
      "Epoch : 17 Test Acc : 80.864\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 1.6500633508 Time : 0.014 seconds \n",
      "Batch Index : 100 Loss : 0.3157146591 Time : 2.108 seconds \n",
      "Batch Index : 200 Loss : 0.3442435807 Time : 3.767 seconds \n",
      "Batch Index : 300 Loss : 0.2964009966 Time : 5.983 seconds \n",
      "Batch Index : 400 Loss : 0.2932069603 Time : 8.401 seconds \n",
      "Batch Index : 500 Loss : 0.3267445053 Time : 10.115 seconds \n",
      "Batch Index : 600 Loss : 0.3271165558 Time : 12.165 seconds \n",
      "Epoch : 18 Test Acc : 82.099\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.3703480661 Time : 0.014 seconds \n",
      "Batch Index : 100 Loss : 0.2555006952 Time : 1.630 seconds \n",
      "Batch Index : 200 Loss : 0.2996661994 Time : 3.584 seconds \n",
      "Batch Index : 300 Loss : 0.3338777093 Time : 5.235 seconds \n",
      "Batch Index : 400 Loss : 0.3285293843 Time : 6.809 seconds \n",
      "Batch Index : 500 Loss : 0.3191634090 Time : 8.455 seconds \n",
      "Batch Index : 600 Loss : 0.3294559834 Time : 10.079 seconds \n",
      "Epoch : 19 Test Acc : 75.309\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.1005368531 Time : 0.014 seconds \n",
      "Batch Index : 100 Loss : 0.3118518642 Time : 1.841 seconds \n",
      "Batch Index : 200 Loss : 0.2557966346 Time : 3.380 seconds \n",
      "Batch Index : 300 Loss : 0.2743374271 Time : 5.001 seconds \n",
      "Batch Index : 400 Loss : 0.2857663577 Time : 6.557 seconds \n",
      "Batch Index : 500 Loss : 0.3040936285 Time : 8.431 seconds \n",
      "Batch Index : 600 Loss : 0.3093128940 Time : 10.103 seconds \n",
      "Epoch : 20 Test Acc : 77.778\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.4074031711 Time : 0.013 seconds \n",
      "Batch Index : 100 Loss : 0.2352122072 Time : 1.779 seconds \n",
      "Batch Index : 200 Loss : 0.2221615664 Time : 3.354 seconds \n",
      "Batch Index : 300 Loss : 0.2358343023 Time : 4.967 seconds \n",
      "Batch Index : 400 Loss : 0.2383014342 Time : 6.639 seconds \n",
      "Batch Index : 500 Loss : 0.2536993790 Time : 8.439 seconds \n",
      "Batch Index : 600 Loss : 0.2512363860 Time : 10.229 seconds \n",
      "Epoch : 21 Test Acc : 77.778\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.1159714311 Time : 0.016 seconds \n",
      "Batch Index : 100 Loss : 0.4920274155 Time : 1.659 seconds \n",
      "Batch Index : 200 Loss : 0.4052889767 Time : 3.337 seconds \n",
      "Batch Index : 300 Loss : 0.3471658833 Time : 5.019 seconds \n",
      "Batch Index : 400 Loss : 0.3565127757 Time : 6.652 seconds \n",
      "Batch Index : 500 Loss : 0.3306759854 Time : 8.706 seconds \n",
      "Batch Index : 600 Loss : 0.3315248516 Time : 10.419 seconds \n",
      "Epoch : 22 Test Acc : 77.778\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.0099609438 Time : 0.014 seconds \n",
      "Batch Index : 100 Loss : 0.3634943037 Time : 1.655 seconds \n",
      "Batch Index : 200 Loss : 0.3082407942 Time : 3.433 seconds \n",
      "Batch Index : 300 Loss : 0.3039692385 Time : 5.194 seconds \n",
      "Batch Index : 400 Loss : 0.2651531458 Time : 6.997 seconds \n",
      "Batch Index : 500 Loss : 0.2668795437 Time : 8.782 seconds \n",
      "Batch Index : 600 Loss : 0.2810238496 Time : 10.443 seconds \n",
      "Epoch : 23 Test Acc : 80.247\n",
      "--------------------------------------------------------------\n",
      "Batch Index : 0 Loss : 0.5755397677 Time : 0.019 seconds \n",
      "Batch Index : 100 Loss : 0.2654910652 Time : 1.605 seconds \n",
      "Batch Index : 200 Loss : 0.2336489496 Time : 3.419 seconds \n",
      "Batch Index : 300 Loss : 0.2710647048 Time : 5.214 seconds \n",
      "Batch Index : 400 Loss : 0.2692319382 Time : 7.081 seconds \n",
      "Batch Index : 500 Loss : 0.2506040681 Time : 9.133 seconds \n",
      "Batch Index : 600 Loss : 0.2588528448 Time : 10.838 seconds \n",
      "Epoch : 24 Test Acc : 77.778\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    losses=[]\n",
    "#     scheduler.step()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for b_idx, x in enumerate(train_loader):\n",
    "#         print(b_idx)\n",
    "        inputs, targets = x['mfcc'].to(device), x['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        op = model(inputs).view(-1)\n",
    "#         print(op[0], targets[0])\n",
    "#         print(type(op.view(-1)[0]), type(targets[0]))\n",
    "#         print(b_idx, op)\n",
    "#         print(targets)\n",
    "        loss = criterion(op, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        end = time.time()\n",
    "        if b_idx % 100 == 0:\n",
    "            print('Batch Index : %d Loss : %.10f Time : %.3f seconds ' % (b_idx, np.mean(losses), end - start))    \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b_idx, x in enumerate(validation_loader):\n",
    "            inputs, targets = x['mfcc'].to(device), x['label'].to(device)\n",
    "\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "#             print(outputs, targets)\n",
    "            predicted = torch.round(outputs.data)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
    "        print('--------------------------------------------------------------')\n",
    "    model.train()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bolo",
   "language": "python",
   "name": "bolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

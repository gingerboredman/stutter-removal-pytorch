{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from pytorch_model_summary import summary\n",
    "import shutil\n",
    "\n",
    "sys.path.insert(1, '../utils')\n",
    "sys.path.insert(1, '../models')\n",
    "\n",
    "from data import StutterData, load_data\n",
    "from audioCNN import AudioCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AudioCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "          Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "===========================================================================\n",
      "   AdaptiveAvgPool2d-1      [1, 1, 20, 50]               0               0\n",
      "              Conv2d-2      [1, 1, 32, 32]              80              80\n",
      "   AdaptiveAvgPool2d-3      [1, 8, 30, 30]               0               0\n",
      "             Dropout-4      [1, 8, 16, 16]               0               0\n",
      "              Conv2d-5      [1, 8, 16, 16]           1,168           1,168\n",
      "   AdaptiveAvgPool2d-6     [1, 16, 14, 14]               0               0\n",
      "              Linear-7           [1, 1024]         524,800         524,800\n",
      "              Linear-8            [1, 512]         131,328         131,328\n",
      "              Linear-9            [1, 256]             257             257\n",
      "===========================================================================\n",
      "Total params: 657,633\n",
      "Trainable params: 657,633\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(AudioCNN(), torch.zeros((1, 1, 20, 50)), show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0079]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.zeros((1, 1, 20, 50)))  # Test forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 1\n",
    "epochs = 25\n",
    "validation_split=0.2\n",
    "shuffle_dataset=True\n",
    "random_seed=42\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")     #Check whether a GPU is present.\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr = 0.00001, momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 200], gamma=0.1)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StutterData('../data/*')\n",
    "train_loader, validation_loader = load_data(dataset, batch_size, validation_split=0.2, shuffle_dataset=True, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioCNN(\n",
       "  (maxpool): AdaptiveAvgPool2d(output_size=32)\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool1): AdaptiveAvgPool2d(output_size=16)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool2): AdaptiveAvgPool2d(output_size=8)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 6])\n",
      "Batch Index : 0 Loss : 1.1542206705 Time : 2.679 seconds \n",
      "torch.Size([1, 20, 33])\n",
      "torch.Size([1, 20, 87])\n",
      "torch.Size([1, 20, 16])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 20, 22])\n",
      "torch.Size([1, 20, 16])\n",
      "torch.Size([1, 20, 47])\n",
      "torch.Size([1, 20, 28])\n",
      "torch.Size([1, 20, 12])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 124])\n",
      "torch.Size([1, 20, 22])\n",
      "torch.Size([1, 20, 75])\n",
      "torch.Size([1, 20, 23])\n",
      "torch.Size([1, 20, 264])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 5])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 81])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 34])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 95])\n",
      "torch.Size([1, 20, 6])\n",
      "torch.Size([1, 20, 20])\n",
      "torch.Size([1, 20, 10])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 15])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 38])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 30])\n",
      "torch.Size([1, 20, 18])\n",
      "torch.Size([1, 20, 290])\n",
      "torch.Size([1, 20, 91])\n",
      "torch.Size([1, 20, 98])\n",
      "torch.Size([1, 20, 15])\n",
      "torch.Size([1, 20, 24])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 21])\n",
      "torch.Size([1, 20, 33])\n",
      "torch.Size([1, 20, 21])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 319])\n",
      "torch.Size([1, 20, 56])\n",
      "torch.Size([1, 20, 78])\n",
      "torch.Size([1, 20, 72])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 42])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 90])\n",
      "torch.Size([1, 20, 6])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 28])\n",
      "torch.Size([1, 20, 35])\n",
      "torch.Size([1, 20, 30])\n",
      "torch.Size([1, 20, 129])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 197])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 41])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 20, 34])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 22])\n",
      "torch.Size([1, 20, 97])\n",
      "torch.Size([1, 20, 24])\n",
      "torch.Size([1, 20, 4])\n",
      "torch.Size([1, 20, 10])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 14])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=2001\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([1, 20, 92])\n",
      "torch.Size([1, 20, 208])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 53])\n",
      "torch.Size([1, 20, 56])\n",
      "torch.Size([1, 20, 207])\n",
      "torch.Size([1, 20, 110])\n",
      "torch.Size([1, 20, 98])\n",
      "torch.Size([1, 20, 70])\n",
      "torch.Size([1, 20, 42])\n",
      "torch.Size([1, 20, 140])\n",
      "torch.Size([1, 20, 62])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 30])\n",
      "torch.Size([1, 20, 18])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 30])\n",
      "torch.Size([1, 20, 30])\n",
      "torch.Size([1, 20, 16])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 27])\n",
      "Batch Index : 100 Loss : 1.1972619561 Time : 5.019 seconds \n",
      "torch.Size([1, 20, 48])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 57])\n",
      "torch.Size([1, 20, 51])\n",
      "torch.Size([1, 20, 164])\n",
      "torch.Size([1, 20, 73])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 23])\n",
      "torch.Size([1, 20, 70])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 52])\n",
      "torch.Size([1, 20, 114])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 43])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 110])\n",
      "torch.Size([1, 20, 29])\n",
      "torch.Size([1, 20, 107])\n",
      "torch.Size([1, 20, 12])\n",
      "torch.Size([1, 20, 4])\n",
      "torch.Size([1, 20, 99])\n",
      "torch.Size([1, 20, 23])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 20, 37])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=2037\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1924\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 4])\n",
      "torch.Size([1, 20, 69])\n",
      "torch.Size([1, 20, 15])\n",
      "torch.Size([1, 20, 19])\n",
      "torch.Size([1, 20, 15])\n",
      "torch.Size([1, 20, 35])\n",
      "torch.Size([1, 20, 24])\n",
      "torch.Size([1, 20, 12])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 58])\n",
      "torch.Size([1, 20, 89])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 34])\n",
      "torch.Size([1, 20, 22])\n",
      "torch.Size([1, 20, 54])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 15])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 10])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 59])\n",
      "torch.Size([1, 20, 108])\n",
      "torch.Size([1, 20, 6])\n",
      "torch.Size([1, 20, 161])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 26])\n",
      "torch.Size([1, 20, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1684\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 4])\n",
      "torch.Size([1, 20, 28])\n",
      "torch.Size([1, 20, 101])\n",
      "torch.Size([1, 20, 38])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 87])\n",
      "torch.Size([1, 20, 22])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 22])\n",
      "torch.Size([1, 20, 24])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 36])\n",
      "torch.Size([1, 20, 66])\n",
      "torch.Size([1, 20, 156])\n",
      "torch.Size([1, 20, 35])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 20, 30])\n",
      "torch.Size([1, 20, 50])\n",
      "torch.Size([1, 20, 4])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 44])\n",
      "torch.Size([1, 20, 21])\n",
      "torch.Size([1, 20, 26])\n",
      "torch.Size([1, 20, 119])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 18])\n",
      "torch.Size([1, 20, 10])\n",
      "torch.Size([1, 20, 46])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 81])\n",
      "torch.Size([1, 20, 69])\n",
      "torch.Size([1, 20, 6])\n",
      "torch.Size([1, 20, 28])\n",
      "torch.Size([1, 20, 1])\n",
      "torch.Size([1, 20, 29])\n",
      "torch.Size([1, 20, 66])\n",
      "torch.Size([1, 20, 61])\n",
      "torch.Size([1, 20, 54])\n",
      "torch.Size([1, 20, 43])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 18])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=87\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Index : 200 Loss : 0.9269539786 Time : 7.416 seconds \n",
      "torch.Size([1, 20, 3])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 20, 121])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1527\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 24])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 69])\n",
      "torch.Size([1, 20, 28])\n",
      "torch.Size([1, 20, 21])\n",
      "torch.Size([1, 20, 157])\n",
      "torch.Size([1, 20, 18])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 40])\n",
      "torch.Size([1, 20, 26])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 12])\n",
      "torch.Size([1, 20, 98])\n",
      "torch.Size([1, 20, 42])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 20])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 360])\n",
      "torch.Size([1, 20, 16])\n",
      "torch.Size([1, 20, 38])\n",
      "torch.Size([1, 20, 38])\n",
      "torch.Size([1, 20, 23])\n",
      "torch.Size([1, 20, 30])\n",
      "torch.Size([1, 20, 47])\n",
      "torch.Size([1, 20, 55])\n",
      "torch.Size([1, 20, 16])\n",
      "torch.Size([1, 20, 6])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 49])\n",
      "torch.Size([1, 20, 36])\n",
      "torch.Size([1, 20, 28])\n",
      "torch.Size([1, 20, 19])\n",
      "torch.Size([1, 20, 42])\n",
      "torch.Size([1, 20, 6])\n",
      "torch.Size([1, 20, 162])\n",
      "torch.Size([1, 20, 166])\n",
      "torch.Size([1, 20, 42])\n",
      "torch.Size([1, 20, 85])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 27])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 66])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 30])\n",
      "torch.Size([1, 20, 46])\n",
      "torch.Size([1, 20, 27])\n",
      "torch.Size([1, 20, 42])\n",
      "torch.Size([1, 20, 40])\n",
      "torch.Size([1, 20, 24])\n",
      "torch.Size([1, 20, 36])\n",
      "torch.Size([1, 20, 6])\n",
      "torch.Size([1, 20, 451])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 74])\n",
      "torch.Size([1, 20, 135])\n",
      "torch.Size([1, 20, 40])\n",
      "torch.Size([1, 20, 51])\n",
      "torch.Size([1, 20, 57])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 40])\n",
      "torch.Size([1, 20, 24])\n",
      "torch.Size([1, 20, 4])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 15])\n",
      "torch.Size([1, 20, 56])\n",
      "torch.Size([1, 20, 24])\n",
      "torch.Size([1, 20, 21])\n",
      "torch.Size([1, 20, 6])\n",
      "torch.Size([1, 20, 60])\n",
      "torch.Size([1, 20, 21])\n",
      "torch.Size([1, 20, 41])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 109])\n",
      "torch.Size([1, 20, 10])\n",
      "torch.Size([1, 20, 228])\n",
      "torch.Size([1, 20, 81])\n",
      "torch.Size([1, 20, 66])\n",
      "torch.Size([1, 20, 18])\n",
      "torch.Size([1, 20, 53])\n",
      "torch.Size([1, 20, 101])\n",
      "torch.Size([1, 20, 49])\n",
      "torch.Size([1, 20, 29])\n",
      "torch.Size([1, 20, 15])\n",
      "torch.Size([1, 20, 42])\n",
      "torch.Size([1, 20, 5])\n",
      "torch.Size([1, 20, 170])\n",
      "torch.Size([1, 20, 26])\n",
      "Batch Index : 300 Loss : 0.8286097468 Time : 10.334 seconds \n",
      "torch.Size([1, 20, 33])\n",
      "torch.Size([1, 20, 86])\n",
      "torch.Size([1, 20, 56])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 127])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 19])\n",
      "torch.Size([1, 20, 31])\n",
      "torch.Size([1, 20, 38])\n",
      "torch.Size([1, 20, 26])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 60])\n",
      "torch.Size([1, 20, 69])\n",
      "torch.Size([1, 20, 54])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 31])\n",
      "torch.Size([1, 20, 37])\n",
      "torch.Size([1, 20, 55])\n",
      "torch.Size([1, 20, 184])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 12])\n",
      "torch.Size([1, 20, 50])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 20, 25])\n",
      "torch.Size([1, 20, 10])\n",
      "torch.Size([1, 20, 4])\n",
      "torch.Size([1, 20, 18])\n",
      "torch.Size([1, 20, 52])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1567\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 58])\n",
      "torch.Size([1, 20, 77])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 27])\n",
      "torch.Size([1, 20, 96])\n",
      "torch.Size([1, 20, 29])\n",
      "torch.Size([1, 20, 59])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 46])\n",
      "torch.Size([1, 20, 10])\n",
      "torch.Size([1, 20, 73])\n",
      "torch.Size([1, 20, 84])\n",
      "torch.Size([1, 20, 65])\n",
      "torch.Size([1, 20, 31])\n",
      "torch.Size([1, 20, 16])\n",
      "torch.Size([1, 20, 11])\n",
      "torch.Size([1, 20, 10])\n",
      "torch.Size([1, 20, 28])\n",
      "torch.Size([1, 20, 18])\n",
      "torch.Size([1, 20, 12])\n",
      "torch.Size([1, 20, 15])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 105])\n",
      "torch.Size([1, 20, 26])\n",
      "torch.Size([1, 20, 30])\n",
      "torch.Size([1, 20, 18])\n",
      "torch.Size([1, 20, 54])\n",
      "torch.Size([1, 20, 8])\n",
      "torch.Size([1, 20, 102])\n",
      "torch.Size([1, 20, 35])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 81])\n",
      "torch.Size([1, 20, 71])\n",
      "torch.Size([1, 20, 79])\n",
      "torch.Size([1, 20, 6])\n",
      "torch.Size([1, 20, 19])\n",
      "torch.Size([1, 20, 46])\n",
      "torch.Size([1, 20, 14])\n",
      "torch.Size([1, 20, 9])\n",
      "torch.Size([1, 20, 17])\n",
      "torch.Size([1, 20, 53])\n",
      "torch.Size([1, 20, 7])\n",
      "torch.Size([1, 20, 10])\n",
      "torch.Size([1, 20, 13])\n",
      "torch.Size([1, 20, 53])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b7745dc59d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mb_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#         print(b_idx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mfcc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/media/Code/stutter-removal-pytorch/utils/data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'non-stuttered'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdct_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   1994\u001b[0m     \"\"\"\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1996\u001b[0;31m     S, n_fft = _spectrogram(\n\u001b[0m\u001b[1;32m   1997\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m         \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36m_spectrogram\u001b[0;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m   2510\u001b[0m         S = (\n\u001b[1;32m   2511\u001b[0m             np.abs(\n\u001b[0;32m-> 2512\u001b[0;31m                 stft(\n\u001b[0m\u001b[1;32m   2513\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2514\u001b[0m                     \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mhop_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_length\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mfft_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfftbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Pad the window out to n_fft size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/filters.py\u001b[0m in \u001b[0;36mget_window\u001b[0;34m(window, Nx, fftbins)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;31m# TODO: if we add custom window functions in librosa, call them here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfftbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfftbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/scipy/signal/windows/windows.py\u001b[0m in \u001b[0;36mget_window\u001b[0;34m(window, Nx, fftbins)\u001b[0m\n\u001b[1;32m   2119\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwinfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/scipy/signal/windows/windows.py\u001b[0m in \u001b[0;36mhann\u001b[0;34m(M, sym)\u001b[0m\n\u001b[1;32m    785\u001b[0m     \"\"\"\n\u001b[1;32m    786\u001b[0m     \u001b[0;31m# Docstring adapted from NumPy's hanning function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgeneral_hamming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/scipy/signal/windows/windows.py\u001b[0m in \u001b[0;36mgeneral_hamming\u001b[0;34m(M, alpha, sym)\u001b[0m\n\u001b[1;32m   1015\u001b[0m            \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mesa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m247904\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1877131\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSentinel\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mProduct\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mDefinition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \"\"\"\n\u001b[0;32m-> 1017\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgeneral_cosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/scipy/signal/windows/windows.py\u001b[0m in \u001b[0;36mgeneral_cosine\u001b[0;34m(M, a, sym)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_truncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_trunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "valid_loss_min = float('inf') #init val_loss\n",
    "checkpoint_path = '../models/audioCNN_ckpt.pth'\n",
    "best_model_path = '../models/audioCNN_best_ckpt.pth'\n",
    "for epoch in range(epochs):\n",
    "    losses=[]\n",
    "#     scheduler.step()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for b_idx, x in enumerate(train_loader):\n",
    "#         print(b_idx)\n",
    "        print(x['mfcc'].shape)\n",
    "        inputs, targets = x['mfcc'].to(device), x['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        op = model(inputs).view(-1)\n",
    "#         print(op[0], targets[0])\n",
    "#         print(type(op.view(-1)[0]), type(targets[0]))\n",
    "#         print(b_idx, op)\n",
    "#         print(targets)\n",
    "        loss = criterion(op, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        end = time.time()\n",
    "        if b_idx % 100 == 0:\n",
    "            print('Batch Index : %d Loss : %.10f Time : %.3f seconds ' % (b_idx, np.mean(losses), end - start))    \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for b_idx, x in enumerate(validation_loader):\n",
    "            inputs, targets = x['mfcc'].to(device), x['label'].to(device)\n",
    "\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "#             print(outputs, targets)\n",
    "            \n",
    "            \n",
    "            predicted = torch.round(outputs.data)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "            valid_loss = criterion(predicted.view(-1), targets.data)\n",
    "            acc = 100.*correct/total\n",
    "        print('Epoch : %d Val_Acc : %.3f Val_loss: %.3f' % (epoch, acc, valid_loss))\n",
    "        print('--------------------------------------------------------------')\n",
    "    checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'valid_loss_min': valid_loss,\n",
    "            'valid_acc': acc,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "\n",
    "    save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "    \n",
    "    if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    model.train()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioCNN(\n",
       "  (maxpool): AdaptiveAvgPool2d(output_size=32)\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool1): AdaptiveAvgPool2d(output_size=16)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool2): AdaptiveAvgPool2d(output_size=8)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loader, _ = load_data(dataset, batch_size, validation_split=0.0, shuffle_dataset=True, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1567\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1684\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=2001\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1527\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1959\n",
      "  warnings.warn(\n",
      "/home/aditya/anaconda3/envs/bolo/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1566\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Val_Acc : 90.629 Val_loss: 0.313\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "acc = 0\n",
    "for b_idx, x in enumerate(validation_loader):\n",
    "            inputs, targets = x['mfcc'].to(device), x['label'].to(device)\n",
    "\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "#             print(outputs, targets)\n",
    "            \n",
    "            \n",
    "            predicted = torch.round(outputs.data)\n",
    "#             print(outputs.data[0], predicted.data, targets)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "            valid_loss = criterion(predicted.view(-1), targets.data)\n",
    "            acc = 100.*correct/total\n",
    "print('Epoch : %d Val_Acc : %.3f Val_loss: %.3f' % (epoch, acc, valid_loss))\n",
    "print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_fpath = '../models/audioCNN_best_ckpt.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 71])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i['mfcc'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,optimizer, chkpt, v_loass = load_ckp(checkpoint_fpath, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-ebe83f8364c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/pytorch_model_summary/model_summary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, batch_size, show_input, show_hierarchical, print_summary, max_depth, show_parent_layers, *inputs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bolo/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_audio_in_chunks(filename, seg_length=1, zero_fill = False):\n",
    "    '''\n",
    "    Correct stuttered speech in chunks of duration seg_length\n",
    "\n",
    "    Correct each chunk of audio and merge the corrected chunks together. Effectiveness depends on the audio in question and the size of the chunks.\n",
    "\n",
    "    Parameters:\n",
    "    filename (string): The path of the stuttered audio file\n",
    "    seg_length (number): Length of the chunks in seconds\n",
    "    zero_fill (boolean): (Optional) Whether the stuttered bits are removed or replaced with zeroes\n",
    "\n",
    "    Returns:\n",
    "    y (numpy ndarray): The sampled amplitude of the corrected audio\n",
    "    sr (number): The sampling rate of the corrected audio\n",
    "    '''\n",
    "    y, sr = librosa.load(filename)\n",
    "    \n",
    "    # one second long chunks (num_secs * sr) = chunk_length\n",
    "    num_chunks = len(y) // sr\n",
    "    extra = len(y) % sr\n",
    "    corrected_audio = []\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "      audio_segment = y[int(sr * i * seg_length) : int(sr * (i + 1) * seg_length)]\n",
    "      corr_segment, _ = correct_audio_segment(audio_segment, sr, zero_fill=zero_fill)\n",
    "      corrected_audio.extend(corr_segment)\n",
    "    corrected_audio = np.array(corrected_audio)\n",
    "    print('correction complete')\n",
    "    return corrected_audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_audio_segment(y, sr, zero_fill = False):\n",
    "    '''\n",
    "    Correct the audio specified audio chunk\n",
    "\n",
    "    Corrects the audio clip by predicting the threshold corresponding to the maximum amplitude of the chunk, and removing the stuttered clips if zero_fill is set to False, or replacing said clips with zeroes if zero_fill is set to True.\n",
    "\n",
    "    Parameters:\n",
    "    y (list): The sampled amplitude of the soundwave\n",
    "    sr (number): The sampling rate in hertz\n",
    "    zero_fill (boolean): (Optional) Whether the stuttered bits are removed or replaced with zeroes\n",
    "    \n",
    "    Returns:\n",
    "    y (list): The sampled amplitude of the corrected audio segment\n",
    "    sr (number): The sampling rate of the corrected audio segment\n",
    "    '''\n",
    "    if len(y) == 0:\n",
    "      return y, sr\n",
    "    \n",
    "    maxv = max(y)\n",
    "    mfcc = librosa.feature.mfcc(y,sr)\n",
    "#     print(type(mfcc))\n",
    "#     print(.shape)\n",
    "    mfcc = torch.from_numpy(mfcc).view((-1,mfcc.shape[0],mfcc.shape[1]))\n",
    "    st = torch.sigmoid(model(mfcc))\n",
    "    print(st, torch.round(st.data)==0, torch.round(st))\n",
    "    \n",
    "# outputs = torch.sigmoid(model(inputs))\n",
    "# #             print(outputs, targets)\n",
    "\n",
    "\n",
    "#         predicted = torch.round(outputs.data)\n",
    "    if torch.round(st) == 1 :\n",
    "        print('hereee',y.shape, type(y))\n",
    "        return y, sr\n",
    "    else:\n",
    "        return np.array([]), sr\n",
    "#     pred_thresh = model.predict()\n",
    "#     frame_duration = 0.3\n",
    "#     frame_len = int(frame_duration * sr)\n",
    "#     n = len(y)\n",
    "#     num_frames = int(n // frame_len)\n",
    "\n",
    "#     corrected_audio_signal = []\n",
    "\n",
    "#     count = -1\n",
    "\n",
    "#     for i in range(num_frames):\n",
    "#       frame = y[(i) * frame_len : frame_len * (i+1)]\n",
    "#       frame_max = max(frame)\n",
    "#       if (frame_max > pred_thresh):\n",
    "#         count += 1\n",
    "#         corrected_audio_signal[(count)*frame_len:frame_len*(count+1)] = frame\n",
    "#       else:\n",
    "#         if (zero_fill):\n",
    "#           count += 1\n",
    "#           # Zero fill\n",
    "#           corrected_audio_signal[(count)*frame_len:frame_len*(count+1)] = np.repeat([0], frame_len)\n",
    "#         else:\n",
    "#           print('skipped frame with max {}'.format(frame_max))\n",
    "#     corrected_audio_signal = np.array(corrected_audio_signal)\n",
    "    return corrected_audio_signal, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = StutterData('./F_0050_10y9m_1.wav', single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioCNN(\n",
       "  (maxpool): AdaptiveAvgPool2d(output_size=32)\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool1): AdaptiveAvgPool2d(output_size=16)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool2): AdaptiveAvgPool2d(output_size=8)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud = librosa.core.load('./F_0050_10y9m_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2950848,), 22050)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud[0].shape, aud[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7920773960569979"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape[0]/aud[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2337300,)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0111]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.4276]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9696]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.0494]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9922]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9553]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.0639]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9972]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.7386]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.8627]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9916]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9995]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.2804]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9987]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.4097]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9989]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9990]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.5798]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9464]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.1152]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9130]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9921]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9970]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.5589]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9972]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.8271]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9472]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9992]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.1603]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.2449]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.0466]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.0477]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9998]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9999]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.0076]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.5580]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9964]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9995]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.8856]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.5295]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9322]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.1115]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9985]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9666]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9945]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.4586]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.8933]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9996]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.0066]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9963]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.7616]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9914]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9999]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9994]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.7167]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9979]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9503]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.5622]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9995]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.0782]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.4298]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.7795]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9853]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.0099]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9983]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9995]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9965]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.7421]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.3534]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9903]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.4062]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.0739]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.9716]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.8057]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9347]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9976]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9999]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9840]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9375]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.8974]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9432]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.8834]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9840]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.2714]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.5457]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.6884]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.1276]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.6896]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.6963]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.6450]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.3675]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[0.5299]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.7722]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.0490]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.0271]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9966]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9955]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9867]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9287]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.0907]], grad_fn=<SigmoidBackward>) tensor([[True]]) tensor([[0.]], grad_fn=<RoundBackward>)\n",
      "tensor([[1.]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9998]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9997]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[0.9404]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward>) tensor([[False]]) tensor([[1.]], grad_fn=<RoundBackward>)\n",
      "hereee (22050,) <class 'numpy.ndarray'>\n",
      "correction complete\n"
     ]
    }
   ],
   "source": [
    "x = correct_audio_in_chunks(filename='./F_0050_10y9m_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundfile.write('./cor.wav', x[0], x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bolo",
   "language": "python",
   "name": "bolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
